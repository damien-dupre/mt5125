---
title: "MT5125 - Data Analytics - Workshop 2 - Part 2"
subtitle: "Wrapping up Academic Research Reports"
author: "Damien Dupr√©"
date: "Dublin City University"
output:
  xaringan::moon_reader:
    css: ["default", "metropolis", "metropolis-fonts", "css/custom_design.css"]
    lib_dir: libs
    nature:
      beforeInit: "libs/cols_macro.js"
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# libraries --------------------------------------------------------------------
library(DiagrammeR)
library(emo)
library(fontawesome)
library(knitr)
library(nomnoml)
library(plotly)
library(tidyverse)

# general options --------------------------------------------------------------
options(scipen = 999)
set.seed(123)
# chunk options ----------------------------------------------------------------
opts_chunk$set(
  cache.extra = rand_seed, 
  message = FALSE, 
  warning = FALSE, 
  error = FALSE, 
  echo = FALSE,
  cache = FALSE,
  comment = "", 
  fig.align = "center", 
  fig.retina = 3
  )

# functions --------------------------------------------------------------------
rtruncnorm <- function(N, mean = 0, sd = 1, a = -Inf, b = Inf) {
  U <- runif(N, pnorm(a, mean, sd), pnorm(b, mean, sd))
  qnorm(U, mean, sd) 
}

# data -------------------------------------------------------------------------
df_data <- 
  tibble(
    predictor = rtruncnorm(100, mean = 5, sd = 2.5, a = 0, b = 10),
    outcome = 2 + 0.9 * predictor + rnorm(100, mean = 0, sd = 1)
  )

df_lm <- lm(outcome ~ predictor, df_data)

df_data <- df_data %>% 
  mutate(
    b0 = rnorm(100, df_lm$coefficients[["(Intercept)"]], 4),
    b1 = rnorm(100, df_lm$coefficients[["predictor"]], 1)
  )
```

# Academic Reports

Science aims to understand phenomena by identifying the variables that influence them.

An academic paper or report is a piece of evidence explaining a phenomenon. 

**By describing the steps to that have led to this explanation (i.e., hypothetico-deductive approach), an academic paper or report ensures the robustness of the evidence found.**

```{r out.width='70%'}
include_graphics("https://www.azquotes.com/picture-quotes/quote-science-may-be-described-as-the-art-of-systematic-over-simplification-karl-popper-23-44-80.jpg")
```

---

# Essential Concepts to Master

In academic research paper all sections are linked:

.center[**Introduction `r ji("right_arrow")` Literature Review `r ji("right_arrow")` Method `r ji("right_arrow")` Results `r ji("right_arrow")` Discussion & Conclusion**]

--

To understand the statistics in the results section it is essential to identify the concepts presented in each section:

```{nomnoml, fig.width=12, fig.height=3}
#stroke: black
#direction: right
#align: center
[Introduction | Variables]->[Literature Review | Hypotheses]
[Literature Review | Hypotheses]->[Method | Model & Equation]
[Method | Model & Equation]->[Results | Statistical Test]
[Results | Statistical Test]->[Discussion & Conclusion | Interpretation]
```

---
class: inverse, mline, center, middle

# 1. Variables

---

# Type and Role of Variables

- Is way of assigning values (numbers or characters) to labels
- Corresponds to a column in a spreadsheet

Challenge: Identify the **Role** and the **Type** of each variable

--

#### 1. Type of Variables

.pull-left[
- **Continuous**: If values are numbers
- **Categorical**: If values are characters

Note: Distinguish **Categorical Nominal** variables (*e.g.*, Irish, French) vs. **Categorical Ordinal** variables (*e.g.*, XS, S, M, L, XL)

]

.pull-right[
```{r out.width='50%'}
include_graphics("img/jamovi_icons.png")
```
]

--

#### 2. Role of Variables

A variable can have one or the other of these roles (no other role exist):

- **Outcome**: "to be explained" variable as Y (also called Dependent Variable or DV)
- **Predictor**: "doing the explaining" as X (also called Independent Variable or IV)

Note: A variable can be also both but in different hypotheses

---
class: inverse, mline, center, middle

# 2. Hypotheses

---

# Correct Hypothesis Formulation

Hypotheses are:

- Predictions supported by theory/literature
- Affirmations designed to precisely describe the relationships between variables

A hypothesis test consists of a test between two competing hypotheses:

- An alternative hypothesis $H_a$ (also called $H_1$)
- A null hypothesis $H_0$ (pronounced "H-naught")

> For $H_0$, there is no relationship between the variables. $H_a$ is the "challenger" hypothesis, it claims the existence of a relationship.

Only 2 kind of alternative hypotheses can be formulated:

- **Main Effect Hypothesis**: Relationship between 1 Predictor and 1 Outcome
- **Interaction Effect Hypothesis**: Relationship between 2+ Predictors and 1 Outcome

Challenge: **Appropriate Formulation** the hypothesis according to the type of the Predictor

---

# Correct Main Effect Hypothesis

The **Outcome has to be Continuous** but ...

- #### Case 1: Predictor is Continuous 

.small[The {**outcome**} increases when {**predictor**} {*increases/decreases/changes*}]

- #### Case 2: Predictor is Categorical (2 Categories)

.small[The {**outcome**} of {**predictor category 1**} is {*higher/lower/different*} than the {**outcome**} of {**predictor category 2**}]

- #### Case 3: Predictor is Categorical (3 or more Categories)

.small[The {**outcome**} of at least one {**predictor**} category is {*higher/lower/different*} than the other {**predictor**} categories]

---

# Correct Interaction Effect Hypothesis

The **Outcome has to be Continuous** and **whatever the Predictor 1 is** ...

- #### Case 1: Predictor 2 is Continuous

.small[The effect of {**predictor 1**} on {**outcome**} is {*higher/lower/different*} when {**predictor 2**} increases]

- #### Case 2: Predictor 2 is Categorical (2 Categories)

.small[The effect of {**predictor 1**} on {**outcome**} is {*higher/lower/different*} for {**predictor 2 category 1**} than for {**category 2**}]

- #### Case 3: Predictor 2 is Categorical (3 or more Categories)

.small[The effect of {**predictor 1**} on {**outcome**} is {*higher/lower/different*} for at least one of {**predictor 2**}]

--

#### Notes:
1. Predictor 1 and 2 are commutable (can be inverted and produce the same hypothesis)
2. An interaction effect hypothesis is also called moderation effect
3. By default, an interaction effect involves the test of the main effect hypotheses of all Predictors involved

---
class: inverse, mline, center, middle

# 3. Model & Equation

---

# Model & Equation

The basic structure of a statistical model is:

$$Outcome = Model + Error$$

where the $Model$ is a series of predictors that are expressed in hypotheses related to the same outcome.
- Main effect hypotheses are indicated with the predictor name only
- Interaction effect hypotheses are indicated with all predictor names separated by $*$

--

#### Example:

$$Outcome = Pred1 + Pred2 + Pred1 * Pred2 + Error$$

--

To evaluate their relationship with the outcome, each effect hypothesis is related with a coefficient called **Estimate** and represented with $b$ as follow:

$$Outcome = b_0 + b_1 Pred1 + b_2 Pred2 + b_3 Pred1 * Pred2 + Error$$

Note: $b_0$ is the estimate related to the intercept. It is always included, always tested but has no interest in the analysis

---
class: inverse

# The Estimate $b$

.pull-left[
To find the **Estimate** for the intercept and each predictor, all possible lines are calculated and the one with the lowest amount of error is selected
]

.pull-right[
```{r fig.width=5, fig.height=3}
ggplot(df_data, aes(predictor, outcome)) + 
  geom_abline(aes(intercept = b0, slope = b1), alpha = 1/4) +
  geom_point() +
  scale_x_continuous(breaks = c(0, seq(0:10)), limits = c(0, 10)) +
  scale_y_continuous(limits = c(0, 10)) +
  theme(
    # axis.text.x = element_blank(), 
    # axis.text.y = element_blank(),
    text = element_text(size = 20)
  )
```
]

.pull-left[
The **Estimate of the Intercept** corresponds to the value of the Outcome when the Predictor is $0$.

The **Estimate of each Predictor** corresponds to how many units the Outcome increases when the Predictor increase by $1$ unit (slope of the line).

]

.pull-right[
```{r fig.width=5, fig.height=3}
ggplot(df_data, aes(predictor, outcome)) +
  geom_point(color = "gray", size = 2, alpha = 0.5) +
  geom_smooth(method = "lm", fullrange = TRUE, se = FALSE) +
  geom_hline(yintercept = df_lm$coefficients[["(Intercept)"]], color = 'black', size = 0.5, linetype = 'dotted') +
  annotate("text", x = 8, y = df_lm$coefficients[["(Intercept)"]] + 0.5, label = "Intercept \u03b2") +
  annotate('segment', x = 1, xend = 2, y = df_lm$coefficients[["(Intercept)"]] + 1*df_lm$coefficients[["predictor"]], yend = df_lm$coefficients[["(Intercept)"]] + 1*df_lm$coefficients[["predictor"]], color = 'red') +
  annotate('segment', x = 2, xend = 2, y = df_lm$coefficients[["(Intercept)"]] + 1*df_lm$coefficients[["predictor"]], yend = df_lm$coefficients[["(Intercept)"]] + 2*df_lm$coefficients[["predictor"]], color = 'red') +
  annotate("text", x = 3, y = df_lm$coefficients[["(Intercept)"]] + 1.5*df_lm$coefficients[["predictor"]], label = "Predictor \u03b2") +
  scale_x_continuous(breaks = c(0, seq(0:10)), limits = c(0, 10)) +
  scale_y_continuous(limits = c(0, 10)) +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```

]

---

class: inverse

# The Standardized Estimate

.pull-left[
Estimates can't be compared because they usually have different units. However, once standardized ([centred around $0$ with a covariance of $1$](https://en.wikipedia.org/wiki/Standardized_coefficient)), these standardized estimates can be compared. 

**Standardized Estimates also corresponds to the correlation** between the Outcome and the Predictor (i.e., ranges from $\text{-}1$ to $1$ with $0$ being no relationship).

Testing $H_a\,vs\,H_0$ is the exact same thing when using the obtained Estimate or the Standardized Estimate.

However, having a high or low (Standardized) Estimate doesn't mean significant effect.
]

.pull-right[

```{r fig.width=5.5, fig.height=7.4}
df_data <- 
  tibble(
    predictor = rtruncnorm(100, mean = 0, sd = 2.5, a = -5, b = 5),
    outcome = 0.9 * predictor + rnorm(100, mean = 0, sd = 1)
  ) %>% 
  mutate(
    b1 = 0.9
  )

df_data_null <- df_data %>% 
  mutate(
    outcome = rnorm(100, mean = 0, sd = 1),
    b1 = 0
  )

df_data_inverse <- df_data %>% 
  mutate(
    outcome = (max(outcome) + min(outcome)) - outcome,
    b1 = -round(df_lm$coefficients[["predictor"]], 1)
  )

df_data_almost <- df_data %>% 
  mutate(
    outcome = 0.5 * predictor + rnorm(100, mean = 0, sd = 1),
    b1 = 0.5
  )

df_data_almost_inverse <- df_data_almost %>% 
  mutate(
    outcome = (max(outcome) + min(outcome)) - outcome,
    b1 = -0.5
  )

df_data %>% 
  bind_rows(
    df_data_null, 
    df_data_inverse, 
    df_data_almost, 
    df_data_almost_inverse
  ) %>%
  filter(outcome < 10) %>%
  plot_ly(x = ~predictor, y = ~outcome) %>%
  add_markers(color = ~b1, frame = ~b1, ids = ~predictor) %>%
  hide_colorbar() %>%
  animation_opts(frame = 1000, easing = "linear") %>%
  animation_slider(
    currentvalue = list(prefix = "Std. Estimate ", font = list(color = "red"))
  )

```

]

---

# Evaluation of the Significance

Testing for the significance of the effect means evaluating if this estimate $b$ value is significantly **different, higher or lower than 0** as hypothesised in $H_a$:

- $b \neq 0$ means our hypothesis doesn't precise the direction of the change, just that there is a change
- $b > 0$ means our hypothesis indicates that the relationship increases or a group is higher than another group
- $b < 0$ means our hypothesis indicates that the relationship decreases or a group is lower than another group

Note: $H_0$ will always predict that $b = 0$

--

The significance, called $p$-value, is the probability to consider $H_0$ as True. This probability is between 0% and 100% which corresponds to a value between 0.0 and 1.0.

If the $p$-value:

- Is **higher** than 5% or 0.05, then $H_0$ is **accepted**
- Is **lower** than 5% or 0.05, then $H_0$ is **rejected** and $H_a$ is considered as plausible

---

# Model & Equation

A graphic representation of the model's hypothesised effects can be done:
- All the arrows correspond to an hypothesis to be tested
- All the tested hypotheses have to be represented with an arrow

.pull-left[
.center[**A simple arrow is a main effect**]

```{r eval=TRUE}
DiagrammeR::grViz("
digraph rmarkdown {
  graph [rankdir = LR]
  
  node [shape = oval]
  Predictor; Outcome
        
  Predictor -> Outcome [label= Œ≤1]
}
", width = 400, height = 200)
```

]

.pull-right[

.center[**A crossing arrow is an interaction effect**]

```{r}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node [shape = circle]
    'Predictor 1'; Outcome; 'Predictor 2'
    node [shape = point, width = 0, height = 0]
    ''
    
    'Predictor 2' -> '' [label= Œ≤2]
    'Predictor 1' -> '' [arrowhead = none] [label= Œ≤1]
    ''-> Outcome [label= Œ≤3]
    
    subgraph {
      rank = same; 'Predictor 2'; '';
    }
  }", height = 200, width = 400)
```

.center[Note: By default, an interaction effect involves the test of the main effect hypotheses of all Predictors involved]

]

---
class: inverse, mline, center, middle

# 4. Statistical Test

---

# JAMOVI: Stats. Open. Now.

- Can be downloaded or used online on https://www.jamovi.org/
- Book "Learning Statistics with Jamovi" free here: https://www.learnstatswithjamovi.com/

Advantages:
1. Free
2. Simple Interface
3. No Missing Values to Declare
4. No Variable to Recode by Default
5. Ready to Publish Tables and Figures
6. Free Modules for Advanced Statistics (Mediation, Generalized LM, Linear Mixed Model)

Note: In Jamovi ...
- The outcome is called Dependent Variable
- A continuous predictor is a covariate
- A categorical predictor is a factor

---

# Good Practices with Hypothesis Testing

- All hypotheses using the **same Outcome variable have to be tested in the same model** and not separately.

- Even if available, no need to use t-tests or ANOVA separate modules because the **Linear Regression can test all types of hypothesis**.

- **Do not use a correlation matrix to test your hypotheses**, they are excursively dedicated to evaluate correlations between predictors.

- A $p$-value never equals $0$, if you see 0.00 then **round to $p < .001$**.

---
class: title-slide, middle

## 4.1 Hypotheses with Continuous Predictors and with Categorical Predictors Having 2 Categories

---

# Hypothesis Testing

1. Open your file
2. Check the type of your variables
3. **Analyses** > **Regression** > **Linear Regression**
4. Set the Outcome as DV and 
  - **To test the main effect hypotheses**: set the Predictors as Covariates/Factors
  - **To test interaction effect hypotheses**: In Model Builder, select all predictor with `CTRL` (win) or `Command` (mac) and bring them as interaction in the model
  
--
  
Communicate the Results about the full model and each hypothesis:

--

- Use **Model Fit Measure Table** to evaluate the accuracy of the full model

The predictions from a model including all effects are significant/not-significant better than without these effects ( $R^2 = value_{R^2}$, $F(df1,df2) = value_{F}$, $p = value_{p}$)

--

- Use **Model Coefficients Table** to conclude about each hypothesis

The effect of $Predictor$ on $Outcome$ is statistically significant/not-significant, therefore $H_0$ can be rejected/accepted ( $b = value_{estimate}, 95\% CI [lower\,CI, upper\,CI]$, $t(df) = value_t$, $p = value_{p}$).

---
class: title-slide, middle

## 4.2 Hypotheses with Categorical Predictors Having 3 or more Categories

---

# Hypothesis Testing

1. Open your file
2. Check the type of your variables
3. **Analyses** > **Regression** > **Linear Regression**
4. Set the Outcome as DV and 
  - **To test the main effect hypotheses**: set the Predictors as Factors
  - **To test interaction effect hypotheses**: In Model Builder options, select all predictor with `CTRL` (win) or `Command` (mac) and bring them as interaction in the model
5. Tick **ANOVA Test** in Model Coefficient options
  
--
  
Communicate the Results about the full model and each hypothesis:

--

- Use **Model Fit Measure Table** to evaluate the accuracy of the full model

The predictions from a model including all effects are significant/not-significant better than without these effects ( $R^2 = value_{R^2}$, $F(df1,df2) = value_{F}$, $p = value_{p}$)

- Use **Omnibus ANOVA Test Table** to conclude about each hypothesis

The effect of $Predictor$ on $Outcome$ is statistically significant/not-significant, therefore $H_0$ can be rejected/accepted ( $F(df_{predictor}, df_{residual}) = value_F$, $p = value_{p}$).

---
class: inverse, mline, center, middle

# 5. Discussion & Conclusion

---

# Interpret the Analyses

From here...
- There is no number to be shown and no specific guidelines
- Correct interpretation comes if results have been understood and if reasons for the results to be the ones obtained have been identified

```{r out.width='40%'}
include_graphics("https://pbs.twimg.com/media/EhjV0v-XgAEh2pk?format=jpg&name=large")
```

---
class: title-slide, middle

## Live Demo: Replication of Lianga et al. (2018)


---
class: inverse, mline, left, middle

<img class="circle" src="https://github.com/damien-dupre.png" width="250px"/>

# Thanks for your attention and don't hesitate to ask if you have any question!

[`r fa(name = "twitter")` @damien_dupre](http://twitter.com/damien_dupre)  
[`r fa(name = "github")` @damien-dupre](http://github.com/damien-dupre)  
[`r fa(name = "link")` damien-datasci-blog.netlify.app](https://damien-datasci-blog.netlify.app)  
[`r fa(name = "paper-plane")` damien.dupre@dcu.ie](mailto:damien.dupre@dcu.ie)